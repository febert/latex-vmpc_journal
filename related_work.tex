\section{Related Work}\label{sec:rel_work}

\subsection{Reinforcement Learning with external reward signals}
While reinforcement learning \emph{reinforces} good behavior our approach learns a \emph{goal-agnostic} model that can be used across a wide range of tasks, not known at training time.

\subsection{Large-Scale, Self-Supervised Robotic Learning}

In a number of recent works large-scale robotic data collection (often using multiple robots) has been the key factor enabling the automatic acquisition of generalizable features and skills. Several prior works have focused on autonomous data collection for individual skills, such as grasping~\cite{lerrel,google_handeye} or obstacle avoidance~\cite{greg_kahn_uncertainty,crashing}. In contrast to these methods, our approach learns predictive models that can be used to perform a variety of manipulations, and does not require a success measure or reward function during data collection. 

In \cite{pulkit} Agrawal et al. propose learning an inverse model from raw sensory data without any supervision. While these methods demonstrated effective generalization to new objects, they were limited in the complexity of tasks and time-scale at which these tasks could be performed. The method was able to plan single pokes, and then greedily execute multiple pokes in sequence. We observe a substantial improvement in the length and complexity of manipulations that can be performed with our method.

%Thanard's model:
Kurutach et al. use a InfoGAN model \cite{kurutach2018learning} to learn a latent-space describing the environment states in which planning can be performed. The model can be used to obtain a sequence of waypoints in the latent space between the current state and goal-state. The method currently relies on an inverse model to reach the states proposed by the InfoGAN model. So far experiments have been limited to rope rearrangement tasks.

\subsection{Sensory Prediction Models}
We propose to leverage sensory prediction models, in particular video-prediction, to achieve large-scale self-supervised learning. Relevant related work on video-prediction has been carried out in the context of synthetic video game images~\cite{atarioh,recurrentsimulators} and robotic manipulation~\cite{bootsetal,finn_nips,video_pixel_networks}. Video prediction without actions has been studied for unstructured videos~\cite{beyond_mse,convlstm,vondrick} and driving~\cite{prednet,dynamic_filter_networks}. Several works have sought to use more complex distributions for future images, for example by using autoregressive models~\cite{video_pixel_networks,scott_reed}. While this often produces sharp predictions, the resulting models are extremely demanding computationally which would be impractical for real-world robotic control. In this work, we extend video prediction methods that are based on predicting a transformation from the previous image~\cite{finn_nips,dynamic_filter_networks}. Prior work has also sought to predict motion directly in 3D, using 3D point clouds obtained from a depth camera~\cite{se3}, requiring point-to-point correspondences over time, which makes it hard to apply to previously unseen objects. Our predictive model is effective for a wide range of real-world object manipulations and does not require 3D depth sensing or point-to-point correspondences between frames.

