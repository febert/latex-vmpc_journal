\section{Experimental evaluation}

\subsection{Evaluating Skip-connection Neural Advection}
Our experimental evaluation compares the proposed occlusion-aware SNA video prediction model, as well as the improved cost function for planning, with a previously proposed model based on dynamic neural advection (DNA)~\cite{foresight}. We use a Sawyer robot, shown in \autoref{fig:teaser}, to push a variety of objects in a tabletop setting. In the appendix, we include a details on hyperparameters, analysis of sample complexity, and a discussion of robustness and limitations. We evaluate long pushes and multi-objective tasks where one object must be pushed without disturbing another. The supplementary video and links to the code and data are available at \url{https://sites.google.com/view/sna-visual-mpc}

\begin{wrapfigure}{r}{.37\columnwidth}
% \vspace{-0.25in}
\centering
\includegraphics[width=0.30\columnwidth]{images_sna/longdistance_pushing/pushing.pdf}
\caption{
Pushing task. The designated pixel (red diamond) needs to be pushed to the green circle.
\label{fig:long_distance_task}
}
\end{wrapfigure}
\autoref{fig:long_distance_task} shows an example task for the pushing benchmark. We collected 20 trajectories with 3 novel objects and 1 training object. \autoref{table:res_longd} shows the results for the pushing benchmark. The column \textit{distance} refers to the mean distance between the goal pixel and the designated pixel at the final time-step. The column \textit{improvement} indicates how much the designated pixel of the objects could be moved closer to their goal (or further away for negative values) compared to the starting location. The true locations of the designated pixels after pushing were annotated by a human. 

The results in \autoref{table:res_longd} show that our proposed planning cost in \autoref{eq:cost} substantially outperforms the planning cost used in prior work~\cite{foresight}. The performance of the SNA model in these experiments is comparable to the prior DNA model~\cite{foresight} when both use the new planning cost, since this task does not involve any occlusions. Although the DNA model has a slightly better mean distance compared to SNA, it is well within the standard deviation, suggesting that the difference is not significant.

\begin{figure*}
\centering
   \includegraphics[width=1\linewidth]{images_sna/multiobject_qualitative/avoid_obstacle.pdf}
\caption{Left: Task setup with green dot marking the obstacle. Right, first row: the predicted frames generated by SNA. Second row: the probability distribution of the designated pixel on the \textit{moving} object (brown stuffed animal). Note that part of the distribution shifts down and left, which is the indicated goal. Third row: the probability distribution of the designated pixel on the obstacle-object (blue power drill). Although the distribution increases in entropy during the occlusion (in the middle), it then recovers and remains on its original position.
\label{fig:goingaroundocclusion}}
\end{figure*}

\begin{table*}
{\footnotesize
    \begin{center}
    \begin{tabular}{|r|l|l|l|l|}
     \hline
        & \multicolumn{2}{c|}{seen} & \multicolumn{2}{c|}{unseen} \\
      \hline
           & \thead{distance \\ mean, std.} &  \thead{improvement \\ mean, std.} &  \thead{dist. \\ mean, std.} & \thead{improvement \\ mean, std.}  \\
           \hline \hline
           
      random actions & 29.4  $\pm$ 3.2 &  -0.85 $\pm$  2.3 & N/A & N/A \\
       \hline \hline
       \hline
      DNA with distance metric as in \cite{foresight} & 25.9 $\pm$ 12.2 & 5.2$\pm$ 13.7 & 24.6$\pm$10.6 & 2.1$\pm$12.4 \\
       \hline
      DNA with our exp. dist. metric eqn. \ref{eq:cost} & \textbf{9.2 $\pm$7.4} &  \textbf{15. $\pm$  11.5} & \textbf{17.5 $\pm$ 10.2} &  \textbf{8.3 $\pm$ 11.8}\\ 
      \hline
      SNA exp. dist. metric eqn. \ref{eq:cost} (ours)& 13.0 $\pm$  5.6 &  12.4 $\pm$ 8.8 & 18.18 $\pm$ 9.5 & 7.7 $\pm$ 10.5\\
      \hline
    \end{tabular}
    \end{center}
    }
    \caption{Results of the pushing benchmark on 20 different object/goal configurations. Units are pixels in the 64x64 images.}
    \label{table:res_longd}
\end{table*}


\begin{table*}
\centering
{\footnotesize
\begin{tabular}{|r|l|l|l|l|}
 \hline
    & \multicolumn{2}{c|}{seen} & \multicolumn{2}{c|}{unseen} \\
  \hline
        &  \thead{moved imp. \\ mean, std.} &   \thead{stationary imp. \\ mean, std.}  &  \thead{moved imp. \\ mean, std.} &   \thead{stationary imp. \\ mean, std.}  \\
   \hline \hline
  Dynamic Neural Advection, DNA \cite{foresight} & 3.5 $\pm$4.94 &  -1.4 $\pm$ 0.39 & 0.83 $\pm$1.13 &  -1.1 $\pm$ 0.9\\ 
  \hline
  Skip Con. Neural Advection, SNA (ours) & \textbf{8.16 $\pm$ 2.9} &  \textbf{-0.9 $\pm$0.7} & \textbf{10.6 $\pm$ 3.7} & \textbf{-1.5 $\pm$ 0.9} \\
  \hline
\end{tabular}
}

\caption{Results for multi-objective pushing on 8 object/goal configurations with 2 seen and 2 novel objects. Values indicate improvement in distance from starting position, higher is better. Units are pixels in the 64x64 images.} 
\label{table:mult_obj}
    \vspace{-0.2in}
\end{table*}

%The pushing task evaluates the ability of each method to push an object across the table, but does not explicitly study the effect of occlusions. 
To examine how well each approach can handle occlusions, we devised a second task that requires the robot to push one object, while keeping another object stationary. When the stationary object is in the way, the robot must move the goal object around it, as shown in \autoref{fig:goingaroundocclusion} on the left. While doing this, the gripper may occlude the stationary object, and the task can only be performed successfully if the model can make accurate predictions through this occlusion. These tasks are specified by picking one pixel on the target object, and one on the obstacle. The obstacle is commanded to remain stationary, while the target object destination location is chosen on the other side of the obstacle.

We used four different object arrangements, with two training objects and two objects that were unseen during training. We found that, in most of the cases, the SNA model was able to find a valid trajectory, while the prior DNA model was mostly unable to find a solution. \autoref{fig:goingaroundocclusion} shows an example of the SNA model successfully predicting the position of the obstacle through an occlusion and finding a trajectory that avoids the obstacle. These findings are reflected by our quantitative results shown in \autoref{table:mult_obj}, indicating the importance of temporal skip connections.

\subsection{Evaluating Closed loop Visual MPC}

\begin{figure}
\centering
\includegraphics[width=.7\columnwidth]{images_rfr/pushing_score_cdf_robot.pdf}
\caption{\small{Real-world benchmark for pushing with 20 different tasks evaluated on unseen objects. Fraction of runs where final distance (in pixel units of 48x64 image) is lower than threshold. Our method shows a clear gain over OpenCV tracking and predictor propagation.}}
\label{fig:push_bench}
\end{figure}

Our experimental evaluation, conducted using two Rethink Sawyer robotic manipulators, evaluate the ability of our method to learn both prehensile and non-prehensile object relocation tasks entirely through autonomously collected data and self-supervision. In particular, we aim to answer the following questions: (1) How does our MPC approach with self-supervised goal image registration compare to alternative cost functions, such as off-the-shelf tracking, forward prediction via flow-based models, and pixel difference costs? (2) When the robot can continuously retry a task with goal image registration, how much is the success rate for object relocation tasks improved? (3) Can we learn predictive models that enable both non-prehensile and prehensile object manipulation? We also present additional experimental comparisons in a simulated environment.
Videos and visualizations can be found on this webpage: \url{https://sites.google.com/view/robustness-via-retrying}.

\subsubsection{Real-World Experiments}

To train both our prediction and registration models, we collected 20,000 trajectories of pushing motions and 15,000 trajectories with gripper control, where the robot was allowed to randomly move and pick up objects. The data collection process is fully autonomous, requiring human intervention only to replace and change out the objects in front of the robot.
%%SL.06.15: would be nice to have a picture of data collection maybe?
The action space consisted of Cartesian movements along the $x$, $y$, and $z$ axes, and changes in azimuthal orientation of the gripper. For evaluation, we selected novel objects that were never seen during training. The evaluation tasks required the robot to move objects in its environment from a starting state to a goal configuration, and performance was evaluated by measuring the distance between the final object position and goal position. In all experiments, the maximum episode length was 50 time steps.

\subsubsection{Pushing with retrying}
\begin{figure*}
    \centering
    \includegraphics[width=1.0\textwidth]{images_rfr/push_correction.pdf}
    \caption{\small{Applying our method to a pushing task. In the first 3 time instants the object behaves unexpectedly, moving down. The tracking then allows the robot to retry, allowing it to eventually bring the object to the goal.}}
    \label{fig:push_retry}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=1.0\textwidth]{images_rfr/pick_place_plush.pdf}
    \caption{\small{Retrying behaviour of our method combining prehensile and non-prehensile manipulation. In the first 4 time instants shown the agent pushes the object. It then loses the object, and decides to grasp it pulling it all the way to the goal. Retrying is enabled by applying the learned registration to both camera views (here we only show the front view).}}
    \label{fig:discrete}
\end{figure*}

In the first experiment, we aim to evaluate the performance of different visual MPC cost functions, including our proposed self-supervised registration cost. For this experiment, we disable the gripper control, which requires the robot to push objects to the target. We evaluate 20 different pushing tasks that require pushing an object to a target position. For comparisons, we include a baseline where the object is tracked using the ``multiple instance learning tracker'' MIL \cite{babenko2009visual} in OpenCV. Note that our method does not have any prior knowledge of objects -- it is only provided with the position of one designed pixel in the initial and goal images, and must use the learned model to infer that this pixel belongs to an object that can be moved by the robot. We also compare to the visual MPC method proposed by \citet{sna},
%%SL.06.15: fill in citation
which does not track the object explicitly, but relies on the flow-based video prediction model to keep track of the designated pixel, which we call ``predictor propagation.'' We also tested a method where the visual MPC cost is calculated by directly evaluating the error between the predicted image and goal image, but we found that this approach was unable to make meaningful progress in moving the object to the target. Instead it resulted in a policy that always moves the arm to the position indicted in the target image, as the arm accounts for the majority of the movable pixel mass in the image. This can be interpreted as undesirable local minimum which is not present in tracking based cost we propose.

\autoref{fig:push_bench} illustrates that our approach not only outperforms prior work \cite{sna}, but also outperforms the hand-designed object tracker \cite{babenko2009visual}. This is due to the fact that using our learned registration the agent is more frequently able to successfully recovering from situations where the object behaved differently than predicted the model predicted (see \autoref{fig:push_retry}).
%%SL.06.15: fill in discussion about what it does

\subsubsection{Combined prehensile and non-prehensile manipulation.}

\begin{wrapfigure}{r}{.35\columnwidth}
\centering
\includegraphics[width=0.35\columnwidth]{images_rfr/grasping_score_cdf.pdf}
\caption{\small{On the real-world grasping benchmark our method is on par with OpenCV tracking.}}
\label{fig:grasp_bench}
\end{wrapfigure}


In the setting where the gripper is enabled it is part of the task to decide whether to solve a task by prehensile or non-prehensile manipulation. Similarly to the pushing setting we perform a benchmark where we define a set of 20 object relocation tasks and measure the final distance between the object and the target at the end of the episode. Interestingly we observe that in the majority of the cases the agent decides to grasp the object, as can be seen in the supplementary video. \autoref{fig:grasp_bench} shows that the performance of our method is comparable with the performance of OpenCV tracking.


\subsubsection{Simulated Experiments}
%\todo{shorten if necessary}

In order to provide a more controlled comparison, we also set up a realistic simulation environment using MuJoCo \cite{todorov2012mujoco}, which includes a robotic manipulator controlled via Cartesian position control, similar to our real world setup, pushing randomly-generated L-shaped objects with random colors (see details in supplementary materials). 
We trained the same video prediction model in this environment, and set up 50 evaluation tasks where blocks must be pushed to target locations with maximum episode lengths of 120 steps. 
We  compare our proposed registration-based method, ``predictor propagation,'' and ground-truth registration obtained from the simulator, which provides an oracle upper bound on registration performance. \autoref{fig:sim_bench} shows the results of this simulated evaluation, where the x-axis shows different distance thresholds, and the y-axis shows the fraction of evaluation scenarios where each method pushed the object within that threshold. We can see that, for thresholds around 0.1, our method drastically outperforms predictor propagation (i.e., prior work~\cite{sna}), and has a relatively modest gap in performance against ground-truth tracking. This indicates that our registration method is highly effective in guiding visual MPC, despite being entirely self-supervised.

\begin{wrapfigure}{r}{.4\columnwidth}
\centering
\includegraphics[width=0.4\columnwidth]{images_rfr/2obj_scores_ours-predprop-ground-truth-track.pdf}
\caption{\small{Simulated evaluation. Fraction of trajectories with final object distance lower than threshold (higher is better).}}
\label{fig:sim_bench}
\end{wrapfigure}

\subsection{Uncertainty-Aware Control using Stochastic Predictions}
\subsubsection{Simulation}


\subsection{Evaluating Classifier-based cost function}

We study a visual object arrangement task, where different goals correspond to different relative arrangements of a pair of objects. We evaluate our learned classifier on the predictions made by the video prediction model and derive the cost used for planning from the predicted probability of success.

\subsubsection{Real-World Experiments}

To collect data for meta-training the classifier, we randomly select a pair of objects from our set of training objects, and position them into many different relative positions, recording the image for each configuration. One task corresponds to a particular relative positioning of two objects, e.g. the first object to the left of the second, and we construct positive and negative examples for this task by labeling the aforementioned images. We randomly position the arm in each image, as it is not a determiner of task success. A good objective should ignore the position of the arm. We also include randomly-positioned distractor objects in about a third of the collected images.

We evaluate all approaches in three different experimental settings. In the first setting, the goal is to arrange two objects into a specified relative arrangement. The second setting is the same, but with distractor objects present. In the final, most challenging setting, the goal is to achieve two tasks in sequence. We provide positive examples for both tasks, infer the classifier for both task, perform MPC for the first task until completion, followed by MPC for the second task. To evaluate the ability to generalize to new goals and settings, we use novel, held-out objects for all of the task and distractor objects in our evaluation. 

We qualitatively visualize the evaluation in Figure~\ref{fig:qual_plan}. On the left, we show a subset of the five images provided to illustrate the task(s), and on the left, we show the motions performed by the robot. We see that the robot is able to execute motions which lead to a correct relative positioning of the objects.
We quantitatively evaluate each method across 20 tasks, including $10$ unique object pairs. The results, shown in Figure~\ref{fig:planning_results}, indicate that prior methods for learning distance metrics struggle to infer the goal of the task, while our approach leads to substantially more successful behavior on average. 

% \begin{wraptable}{r}{0\columnwidth}
% \begin{tabular}{ll}
% \hline
% Method & Success Rate \\ \hline
% DSAE Distance & 10\% \\
% Pixel Distance & 20\% \\
% Classifier-based Cost & 75\% \\ \hline
% \end{tabular}
% \label{tbl:classifier}
% \end{wraptable}