\section{Trajectory Optimizer}

\begin{algorithm}[ht]
\caption{Planning in Visual MPC}
\label{alg:opt}
\begin{algorithmic}[1]
\State \textbf{Inputs:} Predictive Model $g$, task definition i.e. designated-pixel goal pixel pair or goal image
\For{$t~=~0...T-1$}

\For{$i~=~0...n_{iter}-1$}
\If{$i==0$}
\State \begin{varwidth}[t]{\linewidth}
	Sample $M$ action sequences $\{a^{(m)}_{t:t+H-1}\}$ from \par $\mathcal N(0, I)$ or
	custom sampling distribution
\end{varwidth}
\Else
\State \begin{varwidth}[t]{\linewidth}
	Sample $M$ action sequences ${a^{(m)}_{t:t+H-1}}$ from \par 
	$\mathcal N(\mu^{(i)}, \Sigma^{(i)})$
\end{varwidth}
\EndIf
\State  \begin{varwidth}[t]{\linewidth}
	Use model $g$ to predict future sequences of images $\hat{I}_{t:t+H-1}$ and probability distributions $\hat{P}_{t:t+H-1}$
\end{varwidth}
\State Rank the action sequences using a cost function $c$
\State  \begin{varwidth}[t]{\linewidth}
	Fit a Gaussian to the $k$ best action samples \par 
	yielding $\mu^{(i)}, \Sigma^{(i)}$
\end{varwidth}
\EndFor
\State Apply first action of best action sequence to robot
\EndFor
\end{algorithmic}
\end{algorithm}


\label{sec:optimizer}
The role of the optimizer is to find actions sequences $a_{1:T}$ that minimize the sum of the costs $c_{1:T}$ along the planning horizon $T$. We use a simple stochastic optimization procedure for this, based on the cross-entropy method (CEM), a gradient-free optimization procedure.
CEM consists of iteratively resampling action sequences and refitting Gaussian distributions to the actions with the best predicted cost. Algorithm \ref{alg:opt} illustrates this process.

Although a variety of trajectory optimization methods may be suitable, this gradient-free, stochastic optimization procedure allows us to easily ensure that actions stay within the distribution of actions the model has encountered during training. This is crucial to ensure that the model does not receive out-of-distribution inputs and makes valid predictions. In the appendix \ref{sec:cem_improv} we present a few improvements we made to the CEM optimizer for visual MPC.
%%SL.11.21: This paragraph confuses me. How does gradient-free stochastic optimization constrain the optimizer to stay within the distribution of training states? Without any explanation of a mechanism, this paragraph is not very convincing. My suggestion would be to either list different reasons for using CEM, or provide a more convincing justification.