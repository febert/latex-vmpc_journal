\section{Visual Model Predictive Control}\label{sec:prelim}
\label{sec:vmpc}

In this section we define the visual model-predictive control problem formulation. We assume that the user defines a goal for the robot in one of the following ways: (a) in terms of pixel motion (by clicking on the object that shall be moved and on a destination pixel) or (b) by providing one or several demonstrations. Based on either of these task definitions we create per-time step cost functions $c_t$ which depend on outputs of the video-prediction model conditioning on a sequence of actions $a_{t_0:T}$. To find an action sequence $a_{t_0:T}$ for which $c = \sum_t{c_t}$ over the time steps is minimal we use sampling based planning: A large number of candidate action sequences is sampled and the model's predictions are evaluated using $c$. The first action of the sequence which achieved lowest cost is applied to the robot.

To render the planning process more efficient we use the cross-entropy method (CEM), a gradient-free optimization procedure that consists of iteratively resampling action sequences and refitting Gaussian distributions to the actions with the best predicted cost. Further details can be found in section \ref{sec:optimizer}.

To achieve the best results with imperfect models, the actions are iteratively replanned at each real-world time step $\tau \in \{0,...,\tau_{max}\}$ following the framework of model-predictive control (MPC): at each real-world step $\tau$, the model is used to plan $T$ steps into the future, and the first action of the plan is executed.
At the first real-world time step $\tau=0$, the distribution $P_{t=0, d^{(i)}} $ is initialized as 1 at the location of the designated pixel and zero elsewhere. 



